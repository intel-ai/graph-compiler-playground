name: Run mlp test on requested platforms

on:
    workflow_call:
        inputs:
            conda_env:
                required: true
                type: string
                description: Name of conda env
            compiler:
                required: true
                type: string
                description: Type of JIT to use
            device:
                required: true
                type: string
                description: Type of engine to use
            tag:
                required: true
                type: string
                description: Tag to label this result in DB
            torch_mlir_repo:
                description: Torch-MLIR repository on github
                required: true
                default: intel-ai/torch-mlir
                type: string
            torch_mlir_branch:
                description: Torch-MLIR branch to checkout
                required: true
                default: cpu-proto
                type: string
        secrets:
            DB_URL:
                required: true

jobs:
    mlp_test:
        runs-on:
            - self-hosted
            - glados
        steps:
            - uses: actions/checkout@v4
            - uses: ./.github/actions/initial_setup
              with:
                  conda_env: ${{ inputs.conda_env }}
                  compiler: ${{ inputs.compiler }}
                  torch_mlir_repo: ${{ inputs.torch_mlir_repo }}
                  torch_mlir_branch: ${{ inputs.torch_mlir_branch }}

            - name: Run MLP test on specific compiler
              shell: bash -el {0}
              run: |
                  BATCH_SIZE=$(printf "%04d" ${{ matrix.batch_size }})
                  source ${CONDA}/bin/activate ${{ inputs.conda_env }}

                  export ONEDNN_VERBOSE=0
                  export DL_BENCH_ARGS="--host spr --compiler ${{ inputs.compiler }} --device ${{ inputs.device }} --tag ${{ inputs.tag }} -v --url ${{ secrets.DB_URL }}"
                  source iter.sh
