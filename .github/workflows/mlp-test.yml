name: Run mlp test on requested platforms

on:
    workflow_call:
        inputs:
            conda_env:
                required: true
                type: string
                description: Name of conda env
            compiler:
                required: true
                type: string
                description: Type of JIT to use
            device:
                required: true
                type: string
                description: Type of engine to use
            tag:
                required: true
                type: string
                description: Tag to label this result in DB
            torch_mlir_repo:
                description: Torch-MLIR repository on github
                required: true
                default: intel-ai/torch-mlir
                type: string
            torch_mlir_branch:
                description: Torch-MLIR branch to checkout
                required: true
                default: cpu-proto
                type: string
            runner_labels:
                description: Labels to filter runners
                required: false
                default: '["self-hosted", "spr", "glados"]'
                type: string
            shutdown_cloud_runner:
                description: Whether to shutdown AWS cloud runner
                required: false
                default: true
                type: boolean
        secrets:
            DB_URL:
                required: true

jobs:
    print_inputs:
        runs-on: Linux
        steps:
            - name: Print Inputs
              run: echo "${{ toJSON(github.event.inputs) }}"

    mlp_test:
        runs-on: ${{ fromJSON(inputs.runner_labels) }}
        steps:
            - uses: actions/checkout@v4
            - uses: ./.github/actions/initial_setup
              with:
                  conda_env: ${{ inputs.conda_env }}
                  compiler: ${{ inputs.compiler }}
                  torch_mlir_repo: ${{ inputs.torch_mlir_repo }}
                  torch_mlir_branch: ${{ inputs.torch_mlir_branch }}

            - name: Run MLP test on specific compiler
              shell: bash -el {0}
              run: |
                  source ${CONDA}/bin/activate ${{ inputs.conda_env }}
                  export ONEDNN_VERBOSE=1
                  LABELS='${{ inputs.runner_labels }}'
                  case "${LABELS}" in
                      *spr*) HOST="spr";;
                      *amd*) HOST="amd";;
                      *nvidia*) HOST="cuda";;
                      *cuda*) HOST="cuda";;
                      *glados*) HOST="unknown_glados";;
                      *aws*) HOST="unknown_aws";;
                      *) HOST="unknown";;
                  esac
                  if [[ ${LABELS} = *glados* ]]; then
                      URL="--url ${{ secrets.DB_URL }}"
                  fi
                  export DL_BENCH_ARGS="--host ${HOST} --benchmark mlp --compiler ${{ inputs.compiler }} --device ${{ inputs.device }} --tag ${{ inputs.tag }} -v ${URL}"
                  source iter.sh

            - name: Upload results.db to artifacts when running in AWS
              if: contains(fromJSON(inputs.runner_labels), 'aws')
              uses: actions/upload-artifact@v2
              with:
                  name: results.db
                  path: results.db

            - name: Shutdown AWS cloud runner
              if: contains(fromJSON(inputs.runner_labels), 'aws') && inputs.shutdown_cloud_runner
              shell: bash -el {0}
              run: sudo shutdown -h 0
    
    parse_results:
        runs-on: [self-hosted, glados]
        if: contains(fromJSON(inputs.runner_labels), 'aws')
        needs: mlp_test
        steps:
            - name: Download results.db from artifacts
              uses: actions/download-artifact@v2
              with:
                  name: results.db
                  path: results.db 
            
            - name: Upload results into DB
              shell: bash -el {0}
              run: ls -l results.db
